# file: C:\Users\HP\AppData\Roaming\Python\Python313\site-packages\torchvision\models\vision_transformer.py
# hypothesis_version: 6.148.3

[0.0, 1e-06, 0.02, 2.0, 4.409, 15.378, 17.564, 55.484, 61.555, 75.912, 76.972, 79.662, 81.072, 81.886, 85.146, 85.304, 85.708, 88.064, 88.552, 92.466, 93.07, 94.638, 95.318, 96.18, 97.422, 97.65, 97.73, 98.512, 98.694, 167.295, 330.285, 331.398, 336.604, 361.986, 1016.717, 1161.023, 1164.258, 1169.449, 2411.209, 2416.643, 224, 242, 384, 512, 518, 768, 1000, 1024, 1280, 3072, 4096, 5120, 86567656, 86859496, 88224232, 304326632, 305174504, 306535400, 632045800, 633470440, 'ImageNet-1K', 'ViT_B_16_Weights', 'ViT_B_32_Weights', 'ViT_H_14_Weights', 'ViT_L_16_Weights', 'ViT_L_32_Weights', 'VisionTransformer', '_docs', '_file_size', '_metrics', '_ops', 'acc@1', 'acc@5', 'act', 'bias', 'bicubic', 'categories', 'conv_last', 'head', 'heads', 'image_size', 'license', 'min_size', 'num_classes', 'num_params', 'pre_logits', 'pretrained', 'recipe', 'version', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'weight']